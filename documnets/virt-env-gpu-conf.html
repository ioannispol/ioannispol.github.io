<h1 id="unerwater-image-dataset-and-image-classifier">Unerwater Image Dataset and
    Image Classifier</h1>
<p>This is a complete set of an initial attempt to create a basic dataset
    containing 2 classes of underwater images, a class of pipes and a class with
    the underwater environment generally.</p>
<ul>
    <li>The new dataset can be found <a
            href="https://drive.google.com/file/d/1zsMznVwrxo1gUF-1sQYIh0UID05IDcSS/view?usp=sharing">here</a></li>
</ul>
<h1 id="anaconda-configuration-for-cpu-and-gpu">Anaconda configuration for CPU
    and GPU</h1>
<p>Deploying a Machine Learning and Deep Learning poject is not always straight
    forward particularly when we need to run the model in the GPU, if there is
    one in our machine. First of all, we need to have a GPU that suports the
    CUDA library. The list of the CUDA supported GPUs can be found <a
        href="https://developer.nvidia.com/cuda-GPUs">here</a>. The next stpep
    is to specify which framework we intend to use for our deployment, it will
    be TensorFlow, Pytorch, MXNET etc, for this example we will use the
    TensorFlow.</p>
<p>Before installing anything it is the best practice to use virtual
    environments to install the specific versions that we want, and keep the
    main system intact, otherwise by installing different versions for different
    projects we will face mant difficulties with the conflicted libries. Here
    we’ll use Anaconda to setup our virtual environments.</p>
<h2 id="installing-anaconda">Installing Anaconda</h2>
<p>The cool thing using Anaconda is that allows as to install the required from
    the GPU drivers and not bother to install the drivers locally to the
    machine, which could be rather a messy procedure. The other best thing when
    using Anaconda environments is that we can have differnt environments with
    different CUDA and TensorFlow versions. Also by installing Anaconda Python
    is included.</p>
<p>I am using the Miniconda version which is much lighter than the full Anaconda
    version, and the linux version can be downloaded from <a
        href="https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh">here</a>.
    After the isntallation has finished we need to exit the terminal and open it
    again in order the installation of Anaconda to take effect.</p>
<p>Before we steup the environment need to find the correct versions of CUDA,
    cuDNN, etc required by <a href="https://www.tensorflow.org/install/gpu">TensorFlow</a>.</p>
<h2 id="tensorflow-requirements">TensorFlow Requirements</h2>
<p>To istall <strong>TensorFlow 2.4</strong> and <strong>TensorFlow 2.4 GPU</strong>
    we need: 1. Python 3.5 - 3.8 2. For Linux, Ubuntu 16.04 or later (we can use
    other Ubuntu based distros as well) 3. <a
        href="https://www.nvidia.com/drivers">NVIDIA® GPU drivers</a> —CUDA®
    11.0 requires 450.x or higher. 4. <a
        href="https://developer.nvidia.com/cuda-toolkit-archive">CUDA® Toolkit</a>
    —TensorFlow supports CUDA® 11 (TensorFlow &gt;= 2.4.0) 5. <a
        href="http://docs.nvidia.com/cuda/cupti/">CUPTI</a> ships with the CUDA®
    Toolkit. 6. <a href="https://developer.nvidia.com/cudnn">cuDNN SDK 8.0.4</a>
    <a href="https://developer.nvidia.com/rdp/cudnn-archive">cuDNN versions</a>.
    7. (Optional) <a
        href="https://docs.nvidia.com/deeplearning/sdk/tensorrt-install-guide/index.html">TensorRT
        6.0</a> to improve latency and throughput for inference on some models.</p>
<h2 id="search-anaconda-repos-for-the-needed-packages">Search Anaconda repos for
    the needed packages</h2>
<p>Since, we’ll use conda environments to install all the necessary drivers,
    only we need to ensure that the machine has the corect Nvidia GPU drivers
    (450.x or higher). Then we need to make check Anaconda ropsitories to find
    if the above drivers existing. Fortunatly, we can make use of the
    conda-forge channel, as well as the nvidia channel to install these drivers.
    We can do that as follows:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode zsh"><code class="sourceCode zsh"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true"></a>conda search cuda</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true"></a>Loading channels: <span class="kw">done</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true"></a>No match found for: cuda<span class="kw">.</span> Search: *cuda*</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true"></a><span class="co"># Name                       Version           Build  Channel             </span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true"></a>cudatoolkit                      9.0      h13b8566_0  pkgs/main           </span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true"></a>cudatoolkit                      9.2               0  pkgs/main           </span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true"></a>cudatoolkit                 10.0.130               0  pkgs/main           </span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true"></a>cudatoolkit                 10.1.168               0  pkgs/main           </span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true"></a>cudatoolkit                 10.1.243      h6bb024c_0  pkgs/main           </span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true"></a>cudatoolkit                  10.2.89      hfd86e86_0  pkgs/main           </span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true"></a>cudatoolkit                  10.2.89      hfd86e86_1  pkgs/main           </span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true"></a>cudatoolkit                 11.0.221      h6bb024c_0  pkgs/main</span></code></pre></div>
<p>For cudnn will use the nvidia chanel:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode zsh"><code class="sourceCode zsh"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true"></a>conda search -c nvidia cudnn</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true"></a>Loading channels: <span class="kw">done</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true"></a><span class="co"># Name                       Version           Build  Channel                       </span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true"></a>cudnn                          8.0.0      cuda10.2_0  nvidia              </span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true"></a>cudnn                          8.0.0      cuda11.0_0  nvidia              </span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true"></a>cudnn                          8.0.4      cuda10.1_0  nvidia              </span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true"></a>cudnn                          8.0.4      cuda10.2_0  nvidia              </span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true"></a>cudnn                          8.0.4      cuda11.0_0  nvidia              </span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true"></a>cudnn                          8.0.4      cuda11.1_0  nvidia</span></code></pre></div>
<p>So, for TF-2.4 we’ll install: 1. Python 3.8 2. cudatoolkit 11.0 3. cudnn
    8.0.4 4. tensorflow-gpu 2.4</p>
<p>Now that we have found the correct versions of the necessary libraries and
    drivers for the TF-2.4, the next step is to create the virtual environment,
    as the official Anaconda <a
        href="https://docs.anaconda.com/anaconda/user-guide/tasks/tensorflow/">documentation</a>
    describes, that will host the packages and libraries required by TensorFlow
    with the following command:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode zsh"><code class="sourceCode zsh"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true"></a>conda create -n tf24-cuda11 <span class="ot">python=</span>3.8</span></code></pre></div>
<p>After crating the <code>tf24-cuda11</code> environment, we install the above
    packages plus the jupyter lab:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode zsh"><code class="sourceCode zsh"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true"></a>conda <span class="kw">install</span> cudatoolkit</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true"></a>conda <span class="kw">install</span> -c nvidia <span class="ot">cudnn=</span>8</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true"></a>pip <span class="kw">install</span> tensorflow-gpu</span></code></pre></div>
<p>The <code>pip install tensorflow-gpu</code> commande will install Tensorflow
    gpu version, Tensorflow estimator, Tensorflow base. We don’t use conda to
    install tensorflow-gpu because the latest tensorflow version in conda repo
    is 2.2 for Linux and 2.3 for Windows. If we do use <code>conda install
        tnsorflow-gpu</code>, it will install also CUDA 10.2 and cuDNN 7.</p>
<p>The <a
        href="https://jupyterlab.readthedocs.io/en/stable/getting_started/installation.html">Jupyter
        Lab</a> can be install from the conda-forge channel:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode zsh"><code class="sourceCode zsh"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true"></a>conda <span class="kw">install</span> -c conda-forge jupyterlab</span></code></pre></div>
<p>In the new version of jupyter lab 3.x the <code>tab</code> completion does
    not work, and we need to downgrade the <code>jedi</code> library to 0.17.2.
    So, actually we install:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode zsh"><code class="sourceCode zsh"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true"></a>conda <span class="kw">install</span> -c conda-forge jupyterlab</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true"></a>conda <span class="kw">install</span> -c conda-forge <span class="ot">jedi=</span>0.17.2</span></code></pre></div>
<p>Additionally, I have created a <code>requiremets.txt</code> to install some
    extra frameworls and libraries such as: 1. Matplotlib 2. OpenCV 3.
    Scikit-learn 4. Pillow, etc</p>
<p>with the following command: <code>pip install -r requiremets.txt</code></p>
<h2 id="register-the-environment">Register the environment</h2>
<p>It is also a good practice to register the ipykernel for the given
    environment. After activating the conda environemt, in this case is <code>conda
        activate tf24-cuda11</code> we use the following command to <a
        href="https://ipython.readthedocs.io/en/stable/install/kernel_install.html">link</a>
    the kernel with the environment using <code>ipykernel install --user --name
        myenv --display-name "my_environment_name"</code>:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode zsh"><code class="sourceCode zsh"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true"></a>ipykernel <span class="kw">install</span> --user --name tf24-cuda11 --display-name <span class="st">&quot;Python 3.8.5 (tf24-cuda11)&quot;</span></span></code></pre></div>
<h2 id="test-the-environment">Test the environment</h2>
<p>After completing the above steps we can test the installation.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true"></a><span class="im">import</span> sys</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true"></a><span class="im">import</span> tensorflow.keras</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true"></a><span class="im">import</span> sklearn <span class="im">as</span> sk</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true"></a></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true"></a><span class="bu">print</span>(<span class="ss">f&quot;Tensor Flow Version: </span><span class="sc">{tf.</span>__version__<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true"></a><span class="bu">print</span>(<span class="ss">f&quot;Keras Version: </span><span class="sc">{</span>tensorflow<span class="sc">.</span>keras<span class="sc">.</span>__version__<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true"></a><span class="bu">print</span>()</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true"></a><span class="bu">print</span>(<span class="ss">f&quot;Python </span><span class="sc">{</span>sys<span class="sc">.</span>version<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true"></a><span class="bu">print</span>(<span class="ss">f&quot;Pandas </span><span class="sc">{pd.</span>__version__<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true"></a><span class="bu">print</span>(<span class="ss">f&quot;Scikit-Learn </span><span class="sc">{sk.</span>__version__<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true"></a>logical_gpus <span class="op">=</span> tf.config.experimental.list_logical_devices(<span class="st">&#39;GPU&#39;</span>)</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true"></a><span class="bu">print</span>(<span class="bu">len</span>(logical_gpus), <span class="st">&quot;Physical GPUs,&quot;</span>, <span class="bu">len</span>(logical_gpus), <span class="st">&quot;Logical GPUs&quot;</span>)</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true"></a><span class="bu">print</span>(<span class="st">&quot;Num GPUs Available: &quot;</span>, <span class="bu">len</span>(tf.config.experimental.list_physical_devices(<span class="st">&#39;GPU&#39;</span>)))</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true"></a></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true"></a>Tensor Flow Version: <span class="fl">2.4.1</span></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true"></a>Keras Version: <span class="fl">2.4.0</span></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true"></a></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true"></a>Python <span class="fl">3.8.5</span> (default, Sep  <span class="dv">4</span> <span class="dv">2020</span>, 07:<span class="dv">30</span>:<span class="dv">14</span>) </span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true"></a>[GCC <span class="fl">7.3.0</span>]</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true"></a>Pandas <span class="fl">1.2.1</span></span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true"></a>Scikit<span class="op">-</span>Learn <span class="fl">0.24.1</span></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true"></a><span class="dv">1</span> Physical GPUs, <span class="dv">1</span> Logical GPUs</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true"></a>Num GPUs Available:  <span class="dv">1</span></span></code></pre></div>
<h2 id="managint-the-environment">Managint the Environment</h2>
<p>So far we have created the environment for TensorFlow 2.4 with the
    appropriate CUDA and cuDNN drivers installed through conda repos. Also, to
    make our life easier, the different libraries installed using the <code>requirements.txt</code>
    file. Now, it’s a good opportunity to export the environment by creating a
    <code>.yml</code> file using the command:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode zsh"><code class="sourceCode zsh"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true"></a>conda <span class="kw">env</span> <span class="kw">export</span> <span class="kw">&gt;</span> tf24-cuda11.yml</span></code></pre></div>
<p>Finallay, with this way, of using Anaconda environments to install CUDA
    drivers, we can install multiple versions of TensorFlow as well as of other
    ML/DL frameworks, without mess the systems libraryries. Also, another way is
    to use Docker containers, more details can be found: * <a
        href="https://www.tensorflow.org/install">In TensorFlow’s installation
        guide</a> * <a
        href="https://blog.kovalevskyi.com/multiple-version-of-cuda-libraries-on-the-same-machine-b9502d50ae77">In
        this Medium article</a> * <a
        href="https://towardsdatascience.com/managing-cuda-dependencies-with-conda-89c5d817e7e1">Managing
        CUDA dependencies with Conda</a></p>
